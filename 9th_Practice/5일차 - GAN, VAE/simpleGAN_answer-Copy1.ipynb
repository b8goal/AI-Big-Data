{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GAN.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_data, train_label), (test_data, test_label) = mnist.load_data()\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "def img_tile(imgs, aspect_ratio=1.0, tile_shape=None, border=1,\n",
    "             border_color=0):\n",
    "    ''' Tile images in a grid.\n",
    "    If tile_shape is provided only as many images as specified in tile_shape\n",
    "    will be included in the output.\n",
    "    '''\n",
    "    imgs = np.array(imgs)\n",
    "    if imgs.ndim != 3 and imgs.ndim != 4:\n",
    "        raise ValueError('imgs has wrong number of dimensions.')\n",
    "    n_imgs = imgs.shape[0]\n",
    "\n",
    "    # Grid shape\n",
    "    img_shape = np.array(imgs.shape[1:3])\n",
    "    if tile_shape is None:\n",
    "        img_aspect_ratio = img_shape[1] / float(img_shape[0])\n",
    "        aspect_ratio *= img_aspect_ratio\n",
    "        tile_height = int(np.ceil(np.sqrt(n_imgs * aspect_ratio)))\n",
    "        tile_width = int(np.ceil(np.sqrt(n_imgs / aspect_ratio)))\n",
    "        grid_shape = np.array((tile_height, tile_width))\n",
    "    else:\n",
    "        assert len(tile_shape) == 2\n",
    "        grid_shape = np.array(tile_shape)\n",
    "\n",
    "    # Tile image shape\n",
    "    tile_img_shape = np.array(imgs.shape[1:])\n",
    "    tile_img_shape[:2] = (img_shape[:2] + border) * grid_shape[:2] - border\n",
    "\n",
    "    # Assemble tile image\n",
    "    tile_img = np.empty(tile_img_shape)\n",
    "    tile_img[:] = border_color\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            img_idx = j + i * grid_shape[1]\n",
    "            if img_idx >= n_imgs:\n",
    "                # No more images - stop filling out the grid.\n",
    "                break\n",
    "            img = imgs[img_idx]\n",
    "            yoff = (img_shape[0] + border) * i\n",
    "            xoff = (img_shape[1] + border) * j\n",
    "            tile_img[yoff:yoff + img_shape[0], xoff:xoff + img_shape[1], ...] = img\n",
    "\n",
    "    return tile_img\n",
    "\n",
    "\n",
    "def plot_network_output(data, reconst_data, generated, step):\n",
    "    num = 8\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=3, ncols=num, figsize=(18, 6))\n",
    "    for i in xrange(num):\n",
    "        ax[(0, i)].imshow(np.squeeze(generated[i]), cmap=plt.cm.gray)\n",
    "        ax[(1, i)].imshow(np.squeeze(data[i]), cmap=plt.cm.gray)\n",
    "        ax[(2, i)].imshow(np.squeeze(reconst_data[i]), cmap=plt.cm.gray)\n",
    "        ax[(0, i)].axis('off')\n",
    "        ax[(1, i)].axis('off')\n",
    "        ax[(2, i)].axis('off')\n",
    "\n",
    "    fig.suptitle('Top: generated | Middle: data | Bottom: recunstructed')\n",
    "#     plt.show()\n",
    "    plt.savefig(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dd050fdb00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "idx = np.random.randint(0, train_data.shape[0])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[idx]\n",
    "# ax1.imshow(sample_data, cmap=plt.cm.Greys);\n",
    "ax1.imshow(np.array(sample_data*255, dtype=np.uint8), 'gray')\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete summary folder and make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DIR = './gan_summary'\n",
    "TRAIN_DIR = SUMMARY_DIR + '/train'\n",
    "TEST_DIR = SUMMARY_DIR + '/test'\n",
    "IMAGE_DIR = SUMMARY_DIR + '/image'\n",
    "\n",
    "if os.path.exists(SUMMARY_DIR):\n",
    "    shutil.rmtree(SUMMARY_DIR)\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    os.makedirs(TEST_DIR)\n",
    "    os.makedirs(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-73800c37b419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;31m# Build discriminator where input data is real image x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m \u001b[0mD_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;31m# Build generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-73800c37b419>\u001b[0m in \u001b[0;36mdiscriminator\u001b[1;34m(x, reuse)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Return the final tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfully_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fc1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfully_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fc2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-73800c37b419>\u001b[0m in \u001b[0;36mfully_connected\u001b[1;34m(inputs, out_channel, name)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# fc : [batch_size, n] * [n, out_channel] = [batch_size, out_channel]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# weights : [n, out_channel]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mshp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         weights = tf.get_variable('w', \n\u001b[0;32m     21\u001b[0m                                   \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_channel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def fully_connected(inputs, out_channel, name='fc'):\n",
    "    \"\"\"\n",
    "    very simple fully connected layer function\n",
    "\n",
    "    Args:\n",
    "        inputs: a batch of input tensor [batch_size, n]\n",
    "                where n is the number of input feature dimension\n",
    "        out_channel: output channel dimension\n",
    "\n",
    "    Returns:\n",
    "        fc: inputs * weights + biases [batch_size, out_channel]\n",
    "    \"\"\"\n",
    "    # Define weight matrix variable, bias vector variable\n",
    "    with tf.variable_scope(name):\n",
    "        # To share the variables you have to use\n",
    "        # a function 'tf.get_variable' instead of 'tf.Variable'\n",
    "        # fc : [batch_size, n] * [n, out_channel] = [batch_size, out_channel]\n",
    "        # weights : [n, out_channel]\n",
    "        shp = inputs.get_shape().as_list[1]\n",
    "        weights = tf.get_variable('w', \n",
    "                                  shape= [shp,out_channel],\n",
    "                                  initializer=tf.initializers.truncated_normal)\n",
    "        # 성능을 잘 내려면 batch size나 initialize를 바꿔주자.\n",
    "        # glorot_normal weight가 Sigmoid 통과 했을 때 잘나온다\n",
    "        # he_normal weight가 Relu 통과 했을 때 잘나온다\n",
    "        biases = tf.get_variable('b', \n",
    "                                 shape= [shp.out_channel],\n",
    "                                 initializer=tf.initializers.zeros)\n",
    "        \n",
    "        fc = tf.reduce_sum(tf.matmul(inputs,weight),biases)\n",
    "        # fc = tf.matmul(inputs, weights) + biases\n",
    "        # fc = inputs @ weights + biases\n",
    "        # @ : matrix 곱\n",
    "        # * : elementwise 곱이 될 수 있다.\n",
    "        return fc\n",
    "\n",
    "\n",
    "def discriminator(x, reuse=None):\n",
    "    \"\"\"\n",
    "    build the discriminator\n",
    "\n",
    "    Args:\n",
    "        x: a batch of input to the network [batch_size, 28, 28, 1]\n",
    "\n",
    "    returns:\n",
    "        net: output of the discriminator [batch_size, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # Vectorize the input x\n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 1 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'sigmoid'\n",
    "        # Return the final tensor\n",
    "        net = tf.reshape(x,[-1,28*28*1])\n",
    "        net = fully_connected(x,256,'fc1')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = fully_connected(net, 1, 'fc2')\n",
    "        net = tf.nn.sigmoid(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "def generator(z):\n",
    "    \"\"\"\n",
    "    build the generator\n",
    "\n",
    "    Args:\n",
    "        z: a batch of input to the network [batch_size, z_dim]\n",
    "\n",
    "    Returns:\n",
    "        net: output of the generator [batch_size, 28, 28, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "\n",
    "        # Unlike the discriminator, input z is a set of vectors\n",
    "        \n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 784 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'sigmoid'\n",
    "        # Reshape final output to be a proper image file [28, 28, 1]\n",
    "        # Return the final tensor\n",
    "        net = fully_connected(net,256,'fc1')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = fully_connected(net,784,'fc2')\n",
    "        net = tf.nn.sigmoid(net)\n",
    "        net = tf.reshape(28,28,1)\n",
    "        return net\n",
    "\n",
    "\n",
    "def get_loss(D_real, D_fake, eps=1e-10):\n",
    "    \"\"\"\n",
    "    get loss of GAN\n",
    "\n",
    "    Args:\n",
    "        D_real: Real Discriminator output [batch_size, 1]\n",
    "        D_rake: Fake discriminator output [batch_size, 1]\n",
    "\n",
    "    Returns:\n",
    "        D_loss: Discriminator loss\n",
    "        G_loss: Generator loss\n",
    "    \"\"\"\n",
    "    D_loss = tf.reduce_mean(tf.log(D_real + eps)) + tf.reduce_mean(tf.log(D_fake + eps))\n",
    "    G_loss = tf.reuce_mean(tf.log(D_fake + eps))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "\n",
    "\n",
    "def get_next_batch(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    get 'batch_size' amount of data and label randomly\n",
    "\n",
    "    Args:\n",
    "        data: data\n",
    "        label: label\n",
    "        batch_size: # of data to get\n",
    "\n",
    "    Returns:\n",
    "        batch_data: data of 'batch_size'\n",
    "        batch_label: coresponding label of batch_data\n",
    "    \"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    random_idx = random.sample(range(1, n_data), batch_size)\n",
    "\n",
    "    batch_data = data[random_idx]\n",
    "    batch_label = label[random_idx]\n",
    "    return batch_data, batch_label\n",
    "\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "z_dim = 128\n",
    "max_step = 20000\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "\n",
    "train_data = np.expand_dims(train_data, 3)\n",
    "test_data = np.expand_dims(test_data, 3)\n",
    "\n",
    "############################# Build the model #############################\n",
    "# Define image tensor x placeholder\n",
    "x = tf.placeholder(tf.float32, [batch_size, 28, 28, 1], name='input_x')\n",
    "# Define z vector as uniform distribution between [-1, 1]\n",
    "z = tf.random_uniform((batch_size, z_dim), -1., 1., name='latent_z')\n",
    "\n",
    "# Build discriminator where input data is real image x\n",
    "D_real = discriminator(x, reuse=False)\n",
    "# Build generator\n",
    "G = generator(z)\n",
    "# Build discriminator where input data is generated image G\n",
    "D_fake = discriminator(G, reuse=True)\n",
    "\n",
    "# Get D_loss and G_loss\n",
    "D_loss, G_loss = get_loss(D_real, D_fake)\n",
    "\n",
    "# Make optimization op\n",
    "opt = tf.train.AdamOptimizer(lr, beta1=beta1)\n",
    "\n",
    "# To update the generator and the discriminator\n",
    "# get their network parameters\n",
    "G_params = [param for param in tf.trainable_variables()\n",
    "            if 'generator' in param.name]\n",
    "D_params = [param for param in tf.trainable_variables()\n",
    "            if 'discriminator' in param.name]\n",
    "\n",
    "# Make train op for each network\n",
    "D_train = opt.minimize(D_loss, var_list=D_params)\n",
    "G_train = opt.minimize(G_loss, var_list=G_params)\n",
    "\n",
    "# Make initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add summary and make op to add summary data to event log\n",
    "tf.summary.scalar('Generator_loss', G_loss)\n",
    "tf.summary.scalar('Discriminator_loss', D_loss)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Define writer\n",
    "    train_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_DIR)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Before train the model, shows train data and save it\n",
    "    batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "    train_tiled = img_tile(batch_x, border_color=1.0)\n",
    "    train_tiled = np.squeeze(train_tiled)\n",
    "    print(\"Training data\")\n",
    "    plt.imshow(train_tiled, cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    plt.imsave(IMAGE_DIR + '/train.png', train_tiled, cmap=plt.cm.gray)\n",
    "    \n",
    "    samples = []\n",
    "    for step in range(max_step):\n",
    "        batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "        \n",
    "        _, d_loss = sess.run([D_train, D_loss], feed_dict={x: batch_x})\n",
    "        _, g_loss = sess.run([G_train, G_loss])\n",
    "        summary = sess.run(merged, feed_dict={x: batch_x})\n",
    "        train_writer.add_summary(summary, step)\n",
    "        \n",
    "        # Save generarted data to make gif files\n",
    "        if step % 50 == 0:\n",
    "            g = sess.run(G)\n",
    "            g_tiled = img_tile(g, border_color=1.0)\n",
    "            g_tiled = np.squeeze(g_tiled)\n",
    "            samples.append(g_tiled)\n",
    "        if step % 200 == 0:\n",
    "            print(\"{} steps |  G_loss: {:.4f}, D_loss: {:.4f}\".format(step, g_loss, d_loss))\n",
    "            plt.imshow(g_tiled, cmap=plt.cm.gray)\n",
    "            plt.show()\n",
    "            plt.imsave(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)),\n",
    "                       g_tiled, cmap=plt.cm.gray)\n",
    "#             plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "# Make gif files\n",
    "imageio.mimsave(SUMMARY_DIR + '/generated.gif', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
